{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ModelScope模型训练平台配置与使用\n",
    "- 1.ModelScope介绍\n",
    "- 2.环境安装与模型下载\n",
    "- 3.模型推理\n",
    "- 4.模型微调\n",
    "- 5.模型部署"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 环境安装\n",
    "您可以使用魔搭社区已经预安装好的 Notebook环境 来使用魔搭社区模型。魔搭社区Notebook为新用户提供了100小时的免费GPU算力和不限时长的免费CPU算力，并预安装了大部分模型可运行的环境依赖。\n",
    "如果您希望在本地开发环境使用魔搭社区的模型，我们推荐使用ModelScope SDK下载模型。您可以使用如下命令安装ModelScope SDK:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "pip install modelscope"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ms-swift是魔搭社区提供的大模型与多模态大模型训练部署框架，现已支持450+大模型与150+多模态大模型的训练（预训练、微调、人类对齐）、推理、评测、量化与部署。模型开发者可以在ms-swift框架中一站式完成围绕大模型的各类需求。目前ms-swift的主要能力包含：\n",
    "\n",
    "🍎 模型类型：支持450+纯文本大模型、150+多模态大模型以及All-to-All全模态模型、序列分类模型、Embedding模型训练到部署全流程。\n",
    "数据集类型：内置150+预训练、微调、人类对齐、多模态等各种类型的数据集，并支持自定义数据集。\n",
    "硬件支持：CPU、RTX系列、T4/V100、A10/A100/H100、Ascend NPU等。\n",
    "🍊 轻量训练：支持了LoRA、QLoRA、DoRA、LoRA+、ReFT、RS-LoRA、LLaMAPro、Adapter、GaLore、Q-Galore、LISA、UnSloth、Liger-Kernel等轻量微调方式。\n",
    "分布式训练：支持分布式数据并行（DDP）、device_map简易模型并行、DeepSpeed ZeRO2 ZeRO3、FSDP等分布式训练技术。\n",
    "量化训练：支持对BNB、AWQ、GPTQ、AQLM、HQQ、EETQ量化模型进行训练。\n",
    "RLHF训练：支持纯文本大模型和多模态大模型的DPO、GRPO、RM、PPO、KTO、CPO、SimPO、ORPO等人类对齐训练方法。\n",
    "🍓 多模态训练：支持对图像、视频和语音不同模态模型进行训练，支持VQA、Caption、OCR、Grounding任务的训练。\n",
    "界面训练：以界面的方式提供训练、推理、评测、量化的能力，完成大模型的全链路。\n",
    "插件化与拓展：支持自定义模型和数据集拓展，支持对loss、metric、trainer、loss-scale、callback、optimizer等组件进行自定义。\n",
    "🍉 工具箱能力：除了对大模型和多模态大模型的训练支持外，还支持其推理、评测、量化和部署全流程。\n",
    "推理加速：支持PyTorch、vLLM、LmDeploy推理加速引擎，并提供OpenAI接口，为推理、部署和评测模块提供加速。\n",
    "模型评测：以EvalScope作为评测后端，支持100+评测数据集对纯文本和多模态模型进行评测。\n",
    "模型量化：支持AWQ、GPTQ和BNB的量化导出，导出的模型支持使用vLLM/LmDeploy推理加速，并支持继续训练。"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
